{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/e2/00cacecafbab071c787019f00ad84ca3185952f6bb9bca9550ed83870d4d/pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5MB)\n",
      "\u001b[K     |################################| 9.5MB 16.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.6/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /opt/conda/lib/python3.6/site-packages (from pandas) (1.19.4)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas) (2019.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.1.5\n",
      "Collecting scikit-learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/4c/6111b9a325f29527d7f262e2ee8c730d354b47a728d955e186dacad57a0d/scikit_learn-0.24.1-cp36-cp36m-manylinux2010_x86_64.whl (22.2MB)\n",
      "\u001b[K     |################################| 22.2MB 19.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=0.11 (from scikit-learn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/5b/bd0f0fb5564183884d8e35b81d06d7ec06a20d1a0c8b4c407f1554691dce/joblib-1.0.0-py3-none-any.whl (302kB)\n",
      "\u001b[K     |################################| 307kB 49.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (1.19.4)\n",
      "Installing collected packages: joblib, threadpoolctl, scikit-learn\n",
      "Successfully installed joblib-1.0.0 scikit-learn-0.24.1 threadpoolctl-2.1.0\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (4.31.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user pandas\n",
    "!pip install --user scikit-learn\n",
    "!pip install --user tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 593      \n",
    "hidden1 = 64      \n",
    "hidden2 = 64\n",
    "hidden3 = 64\n",
    "weight_bit_width = 2\n",
    "act_bit_width = 2\n",
    "num_classes = 1\n",
    "\n",
    "from brevitas.nn import QuantLinear, QuantReLU\n",
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "      QuantLinear(input_size, hidden1, bias=True, weight_bit_width=weight_bit_width),\n",
    "      nn.BatchNorm1d(hidden1),\n",
    "      nn.Dropout(0.5),\n",
    "      QuantReLU(bit_width=act_bit_width),\n",
    "      QuantLinear(hidden1, hidden2, bias=True, weight_bit_width=weight_bit_width),\n",
    "      nn.BatchNorm1d(hidden2),\n",
    "      nn.Dropout(0.5),\n",
    "      QuantReLU(bit_width=act_bit_width),\n",
    "      QuantLinear(hidden2, hidden3, bias=True, weight_bit_width=weight_bit_width),\n",
    "      nn.BatchNorm1d(hidden3),\n",
    "      nn.Dropout(0.5),\n",
    "      QuantReLU(bit_width=act_bit_width),\n",
    "      QuantLinear(hidden3, num_classes, bias=True, weight_bit_width=weight_bit_width)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "trained_state_dict = torch.load(\"state_dict.pth\")[\"models_state_dict\"][0]\n",
    "\n",
    "\n",
    "model.load_state_dict(trained_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 600])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "modified_model = deepcopy(model)\n",
    "W_orig = modified_model[0].weight.data.detach().numpy()\n",
    "# pad the second (593-sized) dimensions with 7 zeroes at the end\n",
    "W_new = np.pad(W_orig, [(0,0), (0,7)])\n",
    "modified_model[0].weight.data = torch.from_numpy(W_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7eff4b05c588>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.spy(modified_model[0].int_weight().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3386"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wint = modified_model[0].int_weight().numpy()\n",
    "np.count_nonzero( Wint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(~Wint.any(axis=1))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wint[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layers = list(filter(lambda x: x.__class__.__name__ == \"QuantLinear\", modified_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3386 of 38400 are nonzeros\n",
      "837 of 4096 are nonzeros\n",
      "137 of 4096 are nonzeros\n",
      "25 of 64 are nonzeros\n"
     ]
    }
   ],
   "source": [
    "for ll in linear_layers:\n",
    "    W_current = ll.int_weight().numpy()\n",
    "    print(\"%d of %d are nonzeros\" % (np.count_nonzero(W_current), W_current.shape[0]*W_current.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "837\n",
      "(64, 64)\n"
     ]
    }
   ],
   "source": [
    "W_current = modified_model[4].int_weight().numpy()\n",
    "print(np.count_nonzero(W_current))\n",
    "print(W_current.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brevitas.core.quant import QuantType\n",
    "from brevitas.nn import QuantIdentity\n",
    "\n",
    "\n",
    "class CybSecMLPForExport(nn.Module):\n",
    "    def __init__(self, my_pretrained_model):\n",
    "        super(CybSecMLPForExport, self).__init__()\n",
    "        self.pretrained = my_pretrained_model\n",
    "        self.qnt_output = QuantIdentity(quant_type=QuantType.BINARY, bit_width=1, min_val=-1.0, max_val=1.0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # assume x contains bipolar {-1,1} elems\n",
    "        # shift from {-1,1} -> {0,1} since that is the\n",
    "        # input range for the trained network\n",
    "        x = (x + torch.tensor([1.0])) / 2.0  \n",
    "        out_original = self.pretrained(x)\n",
    "        out_final = self.qnt_output(out_original)   # output as {-1,1}     \n",
    "        return out_final\n",
    "\n",
    "model_for_export = CybSecMLPForExport(modified_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:15: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "import brevitas.onnx as bo\n",
    "\n",
    "export_onnx_path = \"cybsec-mlp-nids-demo.onnx\"\n",
    "input_shape = (1, 600)\n",
    "bo.export_finn_onnx(model_for_export, input_shape, export_onnx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
